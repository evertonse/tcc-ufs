
\section{Análise Sintática, (\texttt{parser})} \label{section-parser}

O \textit{parser} para a linguagem subconjunto do ambiente \verb|equation| do \LaTeX{} foi desenvolvido utilizando o método de Pratt \textit{Parsing} na linguagem Odin. Neste contexto, denominamos esse subconjunto como \texttt{EquationLang}, que abrange todas as partes essenciais para a definição de BRDFs descritas em \autoref{especificacao-linguagem}, além de sua gramática documentada.

A implementação deste \textit{parser} adota o método de descida recursiva, no qual cada regra de produção da gramática possui uma função de análise correspondente. Este método foi escolhido por priorizar a clareza e simplicidade do código, complementados por comentários detalhados para facilitar a compreensão. A entrada do \textit{parser} consiste nos \textit{tokens} gerados na etapa de análise léxica.


\subsection{Parser}

Diferentemente dos \textit{parsers} tradicionais de descida recursiva, que frequentemente utilizam múltiplas chamadas de função aninhadas para tratar diferentes níveis de precedência, o \textit{parser} aqui implementado organiza as funções de análise de forma hierárquica, com base na precedência dos operadores. Essa abordagem é detalhada no \autoref{alg-pratt-parsing}, que descreve a lógica central para o \textit{parsing} de expressões.

%%%%%%%%%%%%%%%%
Pratt Parsing simplifica a análise sintática de expressões ao tratar precedência e associatividade dinamicamente, sem inflar a gramática. Na abordagem tradicional, precedências são fixadas por meio de várias regras de produção, desmontrado no \autoref{cod-regras-tradicionais}.

\begin{codigo}[htb]
    \caption{\small Regras tradicionais de precendecia por gramática. }
    \label{cod-regras-tradicionais}
\begin{lstlisting}[language=haskell, numbers=none, inputencoding=utf8]
    Expr               = LogicalOrExpr;
    LogicalOrExpr      = LogicalOrExpr      '||' LogicalAndExpr    | LogicalAndExpr;

    LogicalAndExpr     = LogicalAndExpr     '&&' EqualityExpr      | EqualityExpr;

    EqualityExpr       = EqualityExpr       '==' RelationalExpr    | RelationalExpr;   ---  Igualdade


    RelationalExpr     = RelationalExpr     '<' AdditiveExpr       | AdditiveExpr;     ---  Comparação

    AdditiveExpr       = AdditiveExpr       '+' MultiplicativeExpr | MultiplicativeExpr;

    MultiplicativeExpr = MultiplicativeExpr '*' PrimaryExpr        | PrimaryExpr;

    PrimaryExpr        = '(' Expr ')' | NUMBER | Identifier;  --- Expressões primárias

\end{lstlisting}
\end{codigo}


Isso torna a gramática mais longa, necessitando de mais regras que derivam outras regras antes de chegar a um terminal da gramática. Na descrição recursiva, regras são o mesmo que funções, o que significa que os métodos recursivos tradicionais com muitos níveis de precedência fazem mais chamadas recursivas em código, gerando mais lentidão e complexidade na implementação da descrição recursiva a ser mantida. No Pratt Parsing, uma única regra é suficiente:
\verb`Expr = Expr ( '||' | '&&' | '==' | '<' | '+' | '*' ) Expr;`.

A precedência é definida em uma tabela (\autoref{tab-token-precedence}), e o \textit{parser} consulta essa tabela dinamicamente para decidir a ordem de avaliação com base no operador encontrado. Isso reduz a complexidade, facilita alterações e melhora a eficiência do \textit{parser}, resultando em um código mais simples, eficiente e flexível para incluir novos operadores.

Foi usado a notação similiar à original de Pratt \cite{pratt}, as funções \verb"parse_null_denotations" e \texttt{parse\_left\_denotations} desempenham papéis equivalentes às funções \texttt{token.prefixo} e \texttt{token.infixo}, respectivamente, como demonstrado no \autoref{alg1}. Além disso, a abordagem de descida recursiva (top-down) permite que cada regra de produção definida na gramática (\autoref{grammar-ast-pt1}) seja diretamente mapeada para um procedimento em código. Isso pode ser observado, por exemplo, na função de análise do nó \texttt{Start} da AST (\autoref{cod-parsing-start}), que reflete diretamente as regras de produção \texttt{start}, \texttt{decl}, e \texttt{decl\_equation\_begin\_end\_block} especificadas na gramática demonstrada no \autoref{grammar-ast-pt1}.

Do ponto de vista da interface oferecida pelo pacote \texttt{parser}, todo o processo de análise sintática é abstraído em uma única chamada de função (\autoref{cod-func-and-structs}). A função principal, \texttt{parse}, trabalha em conjunto com a estrutura \texttt{Parser} para realizar a análise.

\begin{codigo}[H]
  \caption{\small Parsing de expressão em código Odin.}
        \label{alg-pratt-parsing}
  \begin{lstlisting}[language=C]


parse_expr :: proc(prec_prev: i64) -> ^Expr {
    /* expressions that takes nothing (null) as left operand */
    left := parse_null_denotations()
    /*
    . if current token is left associative or current token has higher precedence
    . than previous precedence then stay in the loop, effectively creating a left leaning
    . sub-tree, else, we recurse to create a right leaning sub-tree.
    */
    for precedence(peek()) > prec_prev + associativity(peek())  {
        /* expressions that needs a left operand such as postfix, mixfix, and infix operator */
        left = parse_left_denotations(left)
    }
    return left
}


  \end{lstlisting}
\end{codigo}

\begin{codigo}[htb]
        \caption{\small Estruturas e Funções do Parser. }
        \label{cod-func-and-structs}
  \begin{lstlisting}[language = C]
Parser :: struct {
    tokens:      []Token,
    cursor:      i64,
    error_count: int,
}

parse :: proc(using p: ^Parser) -> ^ast.Start {
    return parse_start(p)
}
  \end{lstlisting}
\end{codigo}

\begin{codigo}[htb]
    \caption{\small \textit{Parsing} do nó \texttt{Start}. }
        \label{cod-parsing-start}
  \begin{lstlisting}[language=C++]
parse_start :: proc(using p: ^Parser) -> ^ast.Start {
    node := ast.new(ast.Start)
    decls := [dynamic]^ast.Decl{}

    for peek(p).kind != .EOF {
        decl := parse_equation_begin_end_block(p)
        append(&decls, decl)
    }
    node.eof = next(p, Token_Kind.EOF)
    node.decls = decls[:]
    return node
}
    
  \end{lstlisting}
\end{codigo}



\subsection{Gramática}

Para formalizar a gramática da linguagem de entrada (\texttt{EquationLang}), estabelecemos regras detalhadas nos \autoref{grammar-ast-pt1} e \autoref{grammar-ast-pt2}. É apresentado um exemplo de código-fonte de três equações válidas nesta linguagem no \autoref{code-gramatica}, cuja renderização correspondente em \LaTeX{} é ilustrada em \autoref{code-gramatica-rendered}. Nesse exemplo, a primeira equação ($\rho_{d}$) é gerado pela regra \verb"expr_vector_literal". A segunda ($\rho_{s}$), é uma expressão binário derivada pela regra \verb"expr_infix". Já a última representa uma equação que necessitou de mais regras como \verb"expr_grouped" e \verb"expr_prefix".

\label{code-gramatica-rendered} \begin{subequations}
\begin{equation}
    \rho_{d} = \vec{0.3,0.3,0.3}
\end{equation}
\begin{equation}
    \rho_{s} = \vec{0.0,0.2,1.0}*20
\end{equation}
\begin{equation}
f = \frac{\rho_{d}}{\pi} + \frac{\rho_{s}}{8*\pi} *
\frac{({\vec{n}}\cdot{\vec{h}})}
{({\vec{\omega_{o}}}\cdot{\vec{h}}) *
\max(({\vec{n}}\cdot{\vec{\omega_{i}}}),
({\vec{n}}\cdot{\vec{\omega_{o}}}))}
\end{equation}
\end{subequations}


\begin{codigo}[htb]
        \caption{\small Exemplo código escrito na linguagem \texttt{EquationLang}. }
        \label{code-gramatica}
\begin{lstlisting}[language=tex, frame=none]
\begin{equation}
    \rho_{d} = \vec{0.3,0.3,0.3}
\end{equation}

\begin{equation}
    \rho_{s} = \vec{0.0,0.2,1.0}*20
\end{equation}

\begin{equation}
f = \frac{\rho_{d}}{\pi} + \frac{\rho_{s}}{8*\pi} *
\frac{({\vec{n}}\cdot{\vec{h}})}
{({\vec{\omega_{o}}}\cdot{\vec{h}}) *
\max(({\vec{n}}\cdot{\vec{\omega_{i}}}),
({\vec{n}}\cdot{\vec{\omega_{o}}}))}
\end{equation}

\end{lstlisting}
\end{codigo}

\begin{codigo}[H]
        \caption{\small Gramática para \texttt{EquantionLang} parte 1.}
        \label{grammar-ast-pt1}
\begin{lstlisting}[language=haskell, numbers=none, inputencoding=utf8]
    start  = decl* token_eof;

    decl = decl_equation_begin_end_block;

    decl_equation_begin_end_block =
        token_begin token_opencurly 'equation' token_closecurly
        decl_equation
        token_end token_opencurly 'equation' token_closecurly;

    decl_equation = field;

    field = expr token_equal expr;

    expr = expr_identifier
        | expr_number
        | expr_vector_literal
        | expr_grouped
        | expr_prefix
        | expr_infix
        --- É definido para criação de expressões como 5 fatorial
        --- mas não foi discutido pois não foi necessaria para BRDFs
        --- e portanto não passou pela analise semantica
        | expr_postfix
        --- Ressalto que `function_call` e `function_definition` tem a mesma construção.
        --- Apenas diferenciamos pela posição que aparecer, se à esquerda ou à direta de '=' da regra `field`.
        --- por exemplo `a = f(1)`, `f(1)` é uma chamada de função
        --- Já `f(x) = 1` é uma definição de função
        | expr_function_call
        | expr_function_definition
        | token_opencurly expr token_closecurly
    ;

    expr_identifier =
        --- Ex: `\text{id}`
        token_text token_opencurly expr_identifier token_closecurly
        --- Ex: `\vec{id}`
        token_vec token_opencurly expr_identifier token_closecurly
        --- Ex: `id_n`
        | expr_identifier token_underline expr_identifier
        --- Ex: `id_2`
        | expr_identifier token_underline token_number
        --- Ex: `id_{n+1}`
        | expr_identifier token_underline token_opencurly expr token_closecurly
        --- Token especiais como \phi ou \alpha
        | token_identifier
        | token_omega
        | token_theta   | token_phi
        | token_rho     | token_alpha
        | token_beta    | token_sigma
        | token_pi      | token_epsilon
        | token_max     | token_min
    ;

\end{lstlisting}
\end{codigo}

\begin{codigo}[H]
        \caption{\small Gramática para \texttt{EquantionLang} parte 2.}
        \label{grammar-ast-pt2}
\begin{lstlisting}[language=haskell, numbers=none, inputencoding=utf8]
    expr_number = token_number;

    expr_vector_literal = token_vec
        --- Ex: `\vec{1, 1, 1}`
        token_opencurly
        (expr_number token_comma)* expr_number
        token_closecurly
    ;

    expr_grouped = token_openparen expr token_closeparen;

    expr_prefix =
        (token_sqrt | token_exp | token_tan| token_cos | token_sin | token_arctan | token_arccos | token_arcsin | token_minus | token_plus) expr
    ;

    expr_infix = token_frac
        token_opencurly expr token_closecurly
        token_opencurly expr token_closecurly
        | expr token_plus     expr
        | expr token_minus    expr
        | expr token_mul      expr
        | expr token_cross    expr
        | expr token_cmpequal expr
        | expr token_div      expr
        | expr token_caret    expr
    ;

    expr_postfix = expr token_bang;

    expr_function_call = expr token_openparen
        (expr token_comma)* expr
        token_closeparen
    ;

    --- Mesmo que expr_function_call, em etapas posteriores é decidido qual tipo realmente é.
    expr_function_definition = expr token_openparen
        (expr token_comma)* expr
        token_closeparen
    ;
\end{lstlisting}
\end{codigo}

Na definição da gramática (\autoref{grammar-ast-pt1}), adotamos a notação sintática previamente estabelecida na \autoref{section-lexer}, com o adicional que sequências de três hífens ("\verb"---"") representam comentários para o leitor, sem impactar a definição gramatical.

A gramática definida nesta seção abrange regras para expressões, atribuições, agrupamento, literais numéricos e vetores, chamadas de funções, definições de funções e diversos operadores, como \texttt{expr\_prefix} e \texttt{expr\_infix}. O objetivo é fornecer uma linguagem capaz de expressar a sintaxe necessária para definições de BRDFs em \LaTeX{}. 

A tabela de operadores (\autoref{tab-token-precedence}) usada no Pratt Parsing é representada pela função \texttt{precedence\_from\_token}, que mapeia um token para um valor inteiro que representa sua precedência: quanto maior o valor, maior a precedência do operador. É importante observar que alguns tokens podem ser usados tanto como prefixos quanto como infixos, dependendo do contexto. Por exemplo, o token \texttt{(} pode ser um prefixo em uma expressão de agrupamento, como em \textbf{(}$2*3$\textbf{)}, mas também pode ser infixo em uma chamada de função, como em $f$\textbf{(}$x$\textbf{)}. O mesmo comportamento ocorre com o token \texttt{-}, que pode atuar como operador prefixo de negação ou infixo para subtração.


\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Tipo de Token} & \textbf{Prefixo} & \textbf{Precedência}\\ \hline
\texttt{+}            & Sim              & 25                   \\ \hline
\texttt{-}            & Sim              & 25                   \\ \hline
\texttt{(}            & Sim              & 100                  \\ \hline
\texttt{:}            & Sim              & 100                  \\ \hline
\texttt{*}            & Sim              & 100                  \\ \hline
% \texttt{\textasciitilde} & Sim              & 200               \\ \hline
\texttt{!}            & Sim              & 300                  \\ \hline
\texttt{(}            & Não              & 500                  \\ \hline
\texttt{>}            & Não              & 5                    \\ \hline
\texttt{<}            & Não              & 5                    \\ \hline
\texttt{+}            & Não              & 10                   \\ \hline
\texttt{-}            & Não              & 10                   \\ \hline
$\times$              & Não              & 20                   \\ \hline
\texttt{*}            & Não              & 20                   \\ \hline
\texttt{/}            & Não              & 20                   \\ \hline
\texttt{\textasciicircum} & Não           & 30                  \\ \hline
\texttt{!}            & Não              & 400                  \\ \hline
\end{tabular}
\caption{Tabela de Precedência dos Tokens}
\label{tab-token-precedence}
\end{table}


\subsubsection{Estrutura da Árvore de Sintaxe}
Nesta seção, apresentamos os tipos de nós que compõem a árvore de sintaxe abstrata (AST), utilizada no compilador da linguagem \texttt{EquationLang}. A estrutura da AST é formada por diversos tipos de nós que capturam os diferentes elementos da sintaxe da linguagem. Diferente da gramática definida no \autoref{lst-gramatica}, os nós aqui são representados em nível de código. Vale ressaltar que o nó \texttt{Expr}, o mais genérico, possui um campo adicional \texttt{ty\_inferred} do tipo \texttt{Type}. Esse campo será preenchido durante a etapa de análise semântica e utilizado na geração de código. A seguir, listamos a representação semântica de cada nó, detalhando os campos que compõem cada um deles.

@@Fix this
\begin{itemize}
\item \textbf{Node}: Estrutura base para todos os nós da AST.
      \textbf{Campos:}
      \texttt{kind} (\texttt{typeid}), guarda um número que indica qual o tipo do nó.

\item \textbf{Expr}: Representa expressões de forma geral.
      \textbf{Campos:}
      \texttt{expr\_derived} e \texttt{ty\_inferred} (\texttt{Type})

\item \textbf{Decl}: Representa genericamente declarações.

\item \textbf{Start}: O nó raiz da AST.
      \textbf{Campos:}
      \texttt{decls} lista de \texttt{Decl}, \texttt{eof} (\texttt{Token}).

\item \textbf{Decl\_Equation}: representa uma equação.
      \textbf{Campos:}
      \texttt{field} referencia à uma instancia do nó (\texttt{Field}).

\item \textbf{Field}: Representa uma atribuição qualquer, usando o simbolo '='.
      \textbf{Campos:}
      \texttt{name} (\texttt{\^Expr}), \texttt{equals} (\texttt{Token}), \texttt{value} (\texttt{\^Expr}).

\item \textbf{Expr\_Identifier}: Representa identificadores.
      \textbf{Campos:}
      \texttt{identifier} (\texttt{Token}), \texttt{is\_vector} (\texttt{bool}),
      \texttt{sub\_expression} (\texttt{\^Expr}), \texttt{var} (\texttt{Maybe(string)}).

\item \textbf{Expr\_Number}: Representa literais numéricos.
      \textbf{Campos:}
      \texttt{number} (\texttt{Token}).

\item \textbf{Expr\_Vector\_Literal}: Representa vetores literais.
      \textbf{Campos:}
      \texttt{vec} (\texttt{Token}), \texttt{numbers} (\texttt{[]\^Expr\_Number}).

  \item \textbf{Expr\_Grouped}: representa expressões agrupadas, geralmente por \(\), mas é permitido agrupor por \{\}.
      \textbf{Campos:}
      \texttt{open} (\texttt{Token}), \texttt{expr} (\texttt{\^Expr}), \texttt{close} (\texttt{Token}).

  \item \textbf{Expr\_Prefix}: representa expressão com operator prefixo (ex: -3).
      \textbf{Campos:}
      \texttt{op} (\texttt{Token}), \texttt{right} (\texttt{\^Expr}).

  \item \textbf{Expr\_Infix}: representa expressões para operador infixo, isto é entre expressões, (ex: 3+3).
      \textbf{Campos:}
        \texttt{left} (pointeiro de \texttt{Expr}), \texttt{op} (\texttt{Token}), \texttt{right} (pointeiro de \texttt{Expr}).

\item \textbf{Expr\_Function\_Call}: representa chamadas de função.
      \textbf{Campos:}
      \texttt{left} (ponteiro de \texttt{Expr}), \texttt{open} (\texttt{Token}),
      \texttt{exprs} (lista de poteiros de \texttt{Expr}), \texttt{close} (\texttt{Token}).

\item \textbf{Expr\_Function\_Definition}: representa definições de funções.
      \textbf{Campos:}
      \texttt{name} (\texttt{Expr\_Identifier}), \texttt{open} (\texttt{Token}),
      \texttt{parameters} (lista de \texttt{Expr\_Identifier}), \texttt{close} (\texttt{Token}).
\end{itemize}




No \autoref{lexer-subexpression}, é comentado que o \textit{parser} é capaz de lidar com identificadores aninhados, como, por exemplo, \( x_{i_1} \) (\verb"x_{i_1}"). No \autoref{cod-expression-ident-recursive}, apresentamos como esses identificadores são criados recursivamente. O código mostrado faz parte de uma função maior, sendo um recorte de um \texttt{switch}\footnote{\texttt{switch} e \texttt{case} em Odin funcionam da mesma forma que na linguagem de programação \texttt{C}} sobre a enumeração descrita no \autoref{enum-token-kind}. Dentro desse \texttt{switch}, temos um \texttt{case} que reconhece tokens de identificador ou símbolos especiais (\( \omega, \theta, \phi, \rho, \alpha, \beta, \sigma, \pi, \epsilon \)). Ao fazer uma chamada recursiva à função \texttt{parse\_expr}, o \textit{parser} permite a inclusão de subíndices numéricos, subexpresões de identificadores ou até expressões binárias, como \( n+1 \) em \( f_{n+1} \).

Isso confere maior flexibilidade na hora de expressar funções e equações para descrever as BRDFs, sendo muito comum o uso de subíndices numéricos. Na etapa de geração de código, essa capacidade de distinguir identificadores com subíndices é crucial, pois permite tratar semânticamente tokens aparentemente iguais de maneira diferenciada. Por exemplo, embora o primeiro token seja \( f \), \( f_1 \) e \( f_2 \) são semanticamente distintos, permitindo uma distinção precisa entre símbolos com o mesmo nome base, mas com significados diferentes devido aos seus índices.
%%%%%


\begin{codigo}[htb]
    \caption{\small Parte do código de \textit{parsing} de expressão para identificadores. }
        \label{cod-expression-ident-recursive}
  \begin{lstlisting}[language = C]
    case .Identifier,
         .Omega,     // \omega
         .Theta,     // \theta
         .Phi,       // \phi
         .Rho,       // \rho
         .Alpha,     // \alpha
         .Beta,      // \beta
         .Sigma,     // \sigma
         .Pi,        // \pi
         .Epsilon,   // \epsilon
        node := ast.new(ast.Expr_Identifier)
        node.identifier = next(p)
        if peek(p).kind == Token_Kind('_') {
            next(p)
            if peek(p).kind == Token_Kind('{') {
                next(p, '{')
                node.sub_expression = parse_expr(p, prec)
                next(p, '}')
            } else {
                //
                // If we're not using `identifier_{ }` then, we only allow simple number or identifier
                //
                sub_node := ast.new(ast.Expr_Identifier)
                if peek(p).kind == .Number {
                    // We only allow number as sub expressions
                    sub_node.identifier = next_expects_kind(p, .Number)
                } else {
                    sub_node.identifier = next_expects_kind(p, .Identifier, ..SPECIAL_IDENTIFIERS[1:])
                }
                node.sub_expression = sub_node
            }
        }
    
  \end{lstlisting}
\end{codigo}


O \autoref{cod-expression-ident-recursive}, já apresentado, serve como exemplo para outras expressões recursivas, como expressões infixas (operações binárias). Para identificar o token atual, utilizamos a função \texttt{peek()}, que permite visualizar um ou dois tokens à frente e, com isso, decidir qual nó da AST (Árvore de Sintaxe Abstrata) deve ser construído. Após identificar o token, calculamos a variável \texttt{prec}, que indica a precedência do token atual. Com base nessa precedência, fazemos uma ou mais chamadas recursivas à função \texttt{parse\_expr} para processar os campos que requerem expressões aninhadas.

Uma vez que todos os campos necessários estejam preenchidos, a expressão completa é retornada. Esse processo é repetido até que a subárvore de expressões de uma dada equação esteja completamente construída. A análise sintática é concluída quando todas as equações forem adicionadas à AST. Essa estrutura hierárquica das expressões é então anotada com tipos e validada pelo pacote \texttt{checker}, conforme discutido na \autoref{secion-checker}.

No entanto, antes que a validação ocorra, é necessário implementar métodos para realizar a travessia dessa estrutura. O processo de travessia da AST é discutido na seção \autoref{secion-walker}, onde são apresentadas as técnicas para percorrer a árvore e acessar os dados nela contidos, facilitando a análise semântica e a geração de código subsequente.

