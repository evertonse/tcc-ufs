%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% abnTeX2: Modelo de Trabalho Acadêmico em conformidade com 
% as normas da ABNT

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[english, 
               brazil, 
               bsc] %Opções bsc (TCC) e msc (Mestrado)
               {dcomp-abntex2}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Área para adição de pacotes extras
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \usepackage{lipsum} % Retirar para a versão final do documento
\usepackage{float}
\usepackage{pgfgantt}
\usepackage{lscape}

\restylefloat{table}

%Utilize aqui seu pacote preferido para algoritmos
\usepackage[linesnumbered]{algorithm2e}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Compila o indice
\makeindex

\begin{document}

% Seleciona o idioma do documento (conforme pacotes do babel)
\selectlanguage{brazil}

% Retira espaço extra obsoleto entre as frases.
\frenchspacing 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ELEMENTOS PRÉ-TEXTUAIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pretextual


\titulo{Desenvolvimento de um Compilador de BRDFs em \LaTeX  para linguagem de shading GLSL, através da técnica Pratt Parsing} 
\autor{Everton Santos de Andrade Júnior}
\orientador{Dra. Beatriz Trinchão Andrade}
\coorientador{Dr. Gastao Florencio Miranda Junior}
\curso{Ciência da Computação}

\inserirInformacoesPDF

\imprimircapa
\imprimirfolhaderosto*

% \include{Pre_Textual/Dedicatoria}
% \include{Pre_Textual/Agradecimentos}
% \include{Pre_Textual/Epigrafe}
\include{Pre_Textual/Resumo}
% \include{Pre_Textual/Abstract}


% \mostrarlistadeILUSTRACOES
% \mostrarlistadeQUADROS
% \mostrarlistadeTABELAS
% \mostrarlistadeCODIGOS
% \mostrarlistadeALGORITMOS
 
% \include{Pre_Textual/Abreviaturas}
% \include{Pre_Textual/Simbolos}
    
\mostrarSUMARIO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ELEMENTOS TEXTUAIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textual

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Introdução
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Introdução}
\label{introduction}


\section{Contexto}

Na computação gráfica, a representação realista de cenas tridimensionais depende fortemente da modelagem da luz e dos materiais que compõem os objetos na cena. [referencia] A interação da luminosidade incidente com esses materiais é crucial para a geração de imagens fiéis à realidade. Uma abordagem fundamental para modelar essa interação é por meio das funções de distribuição de refletância bidirecional, conhecidas como BRDFs (do inglês, \textit{Bidirectional Reflectance Distribution Functions}).


As BRDFs, essencialmente, calculam a proporção entre a energia luminosa que atinge um ponto na superfície e como essa energia é refletida, transmitida ou absorvida [referencia]. Na renderização, essas funções são implementadas por meio programas especializados nas unidades de processamento gráfico (GPUs), esses programmas são chamados de \textit{shaders}, e cada interface de programação, do inglês \textit{ Application Programming Interface} (API), de rederização disponibiliza etapas diferentes onde esses executaveis podem ser programados durante o processo de renderização. Esses \textit{shaders} concedem a capacidade de cada objeto renderizado ter sua aparência configurada por meio de um código que implementa uma BRDF.


\section{Motivação}

Apesar da disponibilidade de linguagens específicas para a programação de shaders, que possibilitam a modificação procedimentos que representam uma BRDF, a aplicação de BRDFs na geração de \textit{shaders} requer conhecimento especializado em programação [referencia?]. Essa barreira técnica pode restringir a exploração dos efeitos visuais por profissionais de áreas não relacionadas à programação. Diante disso, surge a necessidade de ferramentas mais acessíveis para a criação de \textit{shaders}.

No meio acadêmico, as BRDFs são comumente descritas por fórmulas escritas em \LaTeX , uma abordagem promissora para atender a essa necessidade é o desenvolvimento de um compilador capaz de traduzir BRDFs em \LaTeX  para \textit{shaders}, assim democratizando a visualização dessas BRDFs. Dado que as fórmulas são equações matemáticas, precisamos retrigir representação da linguagem de entrada para o compilador afim de garatir um projeto útil em tempo hábil.

\section{Objetivo}
Este trabalho visa projetar e implementar um compilador que, a partir de BRDFs escritas como equações em \LaTeX, seja capaz de gerar código de \textit{shading} na linguagem alvo da API OpenGL, considerando a precedência de operadores. O resultado será um \textit{shader} capaz de reproduzir as características de reflexão da BRDF original ou, ao menos, alcançar uma aproximação satisfatória dessas características, levando em conta as limitações da linguagem de \textit{shading} da API, principalmente as representações de dados de forma discreta. 

\section{Estrutura do Documento}
No \autoref{conceitos}, descrevemos por todos os conhecimentos necessário para entender BRDFs,incluingo quantificação de luminosidade, e radiação, assim como conceitos de compiladores como tokenização e construção da árvore sintática.
\autoref{radiometria} trata dos conceitos fundamentais relacionados à luz, como a capacidade de um material refletir raios de luz e sua importância na computação gráfica e renderização. Destaca-se a relação entre a intensidade de um pixel de imagem, a iluminação, a orientação e a reflectância da superfície, além da definitição de funções de refletância, as BRDFs. 
\autoref{brdfmodels} destaca algums modelos comuns de BRDFs. é compilador 

Na \autoref{compiladores}, fornece uma visão abrangente dos elementos essenciais envolvidos na criação de compiladores. Começa com a definição de conceitos fundamentais, como cadeias de símbolos e alfabetos, necessários para entender linguagens formais. Em seguida, explora a natureza das linguagens, destacando sua estrutura e semântica. Além disso, a seção discute a importância das gramáticas na definição de linguagens e descreve o processo de compilação, incluindo a análise léxica, a análise sintática e o Pratt \textit{Parsing}, uma técnica eficiente para lidar com a precedência de operadores durante a análise sintática

Na \autoref{shading} aborda o processo de shading em gráficos por computador e o funcionamento do pipeline de renderização da GPU, destacando o papel dos shaders. Descreve a transformação de vértices e a determinação da cor dos fragmentos, mostrando exemplos de código. 

\autoref{revisao}, tem como parte principal um mapeamento sistemático utilizando termos de busca para identificar trabalhos relevantes sobre o desenvolvimento de compiladores para traduzir BRDFs de \LaTeX para shaders. Os critérios de inclusão e exclusão são definidos para filtrar os resultados. Além disso, são descritos os resultados encontrados em diversas bases de dados, como IEEE Xplore, BDTD, CAPES, ACM Digital Library e Google Scholar, bem como a análise de repositórios online como GitHub e SourceForge. 

No \autoref{metodologia}, é descrito o método para desenvolver o compilador proposto, são definidas etapas adaptadas para alcançar os objetivos de pesquisa especificados. Casos de teste são projetados para validação. O plano de continuação, na \autoref{continuacao}, detalha as etapas futuras com datas previstas.

O \autoref{resultadosiniciais} descreve a implementação de um analisador léxico, sintático e interpretador em Odin usando análise de Pratt. Ele prioriza simplicidade e clareza, com uma gramática definida e uma tabela de símbolos simples. O capítulo também detalha testes desenvolvidos para validar a implementação. O segundo capítulo apresenta o desenvolvimento de um \textit{ray tracer} em Odin com RayLib, modelando raios e materiais para renderização de imagens em CPU.





% Apesar da importância de usar técnicas confiáveis para avaliar um BRDF, há uma falta de trabalhos na literatura que reúnam e comparem essas técnicas.
% Este artigo propõe uma compilação de técnicas usadas para avaliar representações de BRDF, juntamente com suas definições formais. Essas técnicas foram classificadas em três grupos diferentes - funções de comparação, imagens renderizadas e gráficos - e, para ilustrar seu uso, três modelos clássicos e amplamente adotados e uma representação de BRDF de ponta foram avaliados quanto à sua capacidade de preservar a aparência de materiais medidos. Com base em nossa pesquisa sobre funções de comparação, uma técnica de avaliação de BRDF estável e robusta é proposta. Observou-se tanto durante a revisão da literatura quanto nos experimentos que cada grupo de técnicas fornece informações complementares sobre os BRDFs avaliados, o que sugere que pelo menos um modelo de cada categoria deve ser adotado durante a escolha de critérios para avaliar um BRDF.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Revisão Bibliográfica 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conceitos} \label{conceitos}

\section{Radiometria} \label{radiometria}

A radiometria trata de conceitos fundamentais relacionados à luz. Ela abrange a capacidade de um material de superfície receber raios de luz de uma direção e refleti-los em outra. No contexto da computação gráfica e renderização, a radiometria desempenha um papel crucial na compreensão do comportamento da luz em uma cena.

A intensidade de um pixel de imagem depende de vários fatores, como iluminação, orientação da superfície e refletância da superfície. A orientação da superfície é determinada pelo vetor normal em um ponto dado, enquanto a refletância da superfície diz respeito às propriedades materiais da mesma.

Para compreender e interpretar a intensidade de um pixel em uma imagem, é essencial compreender os conceitos radiométricos. A radiometria quantifica o brilho de uma fonte de luz, a iluminação de uma superfície, a radiância de uma cena e a refletância da superfície.

Renderização Além da Cor

Renderizar uma imagem envolve mais do que apenas capturar cor. Isso requer conhecimento da intensidade da luz em cada ponto da imagem, isto é, a quantidade de luz incidente na cena que alcança a câmera. A radiometria ajuda na criação de sistemas e unidades para quantificar a radiação eletromagnética, considerando a luz como fótons viajando em linha reta em um modelo óptico geométrico. Esse modelo simplifica considerações de difração e interferência, focando nos caminhos em linha reta dos fótons.

\subsection{Energia Radiante e Fluxo} \label{fluxo}

Vários processos físicos convertem energia em fótons, como radiação de corpo negro e fusão nuclear em estrelas. Quantificar a energia radiante total envolve entender a energia dos fótons colidindo com um objeto, equivalente ao brilho da imagem. A energia radiante $Q$ considera a energia total de todos os fótons atingindo a cena durante toda a duração.

\begin{align*} 
Q &= \frac{hc}{\lambda} \\
  h &\approx 6,626 \times 10^{-34} J \cdot s (\text{Joules por segundo})\\
  c &\approx 3,00  \times 10^{8} m \cdot s (\text{metros por segundo})\\
  \lambda &\approx 390-700  \times 10^{-3} m (\text{metros})
\end{align*}


É interessante observar a evolução da energia radiante $Q$ ao longo do tempo, isso da origem ao fluxo radiantea $\phi$, medida em impactos de cada fóton por segundo em uma superficie.

\begin{align*} 
  \phi &= \frac{dQ}{dt} [\text{J/s}] 
\end{align*}

A irradiância $E$ quantifica o número de impactos dos photons em uma superficie por segundo por unidade de área. Assim, tempos uma métrica mais específica e essencial para renderizar imagens com precisão.

$$
 E(p) = \frac{d\phi(p)}{dA} [\text{J/s} \cdot m^2]
$$


\subsection{Radiância e BRDF} \label{brdf}

A radiância, denotada como $L$, caracteriza a distribuição da luz em um ambiente ao longo de um raio definido por um ponto de origem e uma direção. A radiância desempenha um papel fundamental no cálculo do fluxo por unidade de área em uma superfície considerando toda a luz incidente de todas as direções possiveis em um dado ponto $p$.


\begin{align*} 
  L(p,w) &= \frac{dE_w(p)}{dw} \qquad \left[\frac{J}{s\cdot m^2\cdot \text{sr}}\right]\\ 
E_w &\text{ é função de a irradiancia numa direção $w$ }  \end{align*}


Para acomodar diferentes orientações da superfície e direção do raio, aplicamos o fator $\cos(\theta)$, tal que $\theta$ é o angulo entre a normal da superficie e a direção do $w$ para obter a formula:
\begin{align*} 
  L(p,w) &= \frac{dE(p)}{dw \cos(\theta)} = \frac{d^2\phi(p)}{dAdw \cos(\theta)}
\end{align*}

A radiância pode fornecer informação sobre o quanto um ponto específico está iluminado na direção da câmera. Ela depende não apenas da direção do raio que incide câmera, mas também das propriedades de refletância da superfície. E, no contexto de renderização, a radiância de uma superfície na cena se correlaciona com a irradiância de um pixel em uma imagem da sequinte forma: 

\begin{align*}
  &E(p) = \int_{H^2}{L(p,w)\cos(\theta)dw}\\
  &H^2 \text{ é o hemisfério no plano tangente à superficie no ponto $p$}
\end{align*}


A principal funcionalidade de uma renderizador fotorealista é estimar a radiancia em um ponto $p$ numa dada direção $w_o$. Essa radiancia é dada pela equação de renderização apresentada por @ref Kajiya. Note que essa euquação envolve um termo de radiancia recursiva, o caso base ocorre quando não há mais o termo recursivo, isto é, um fonte de luz na qual sua radiancia é contribuida apenas por randianca emitida $L_e$.

\begin{align*}
  &L_o(p, w_o) = L_e(p, w_o) + 
\int_{H^2}F(p, w_i, w_o){L_i(p,w_i)\cos(\theta)dw_i}\\
    &L_o \text{ é radiancia de saída (\textit{outgoing}) ou {observada}}\\
    &L_e \text{ é radiancia emitida (i.e. fonte de luz)}\\
    &L_i \text{ é radiancia incidente}\\
    &w_i \text{ é a direção incidente}\\
    &w_o \text{ é a direção de saída}\\
    &H^2 \text{ são todas no hemisfério}\\
    &\theta \text{ angulo entre direção incidente e a normal da superficie}\\
    &F \text{ função de refletancia}\\
\end{align*}

A Função de Distribuição Bidirecional de Reflectância (BRDF) descreve como a luz reflete de uma superficie em diferentes direções afetando a radiância de saída. Reflexão é o processo no qual a luz iterage com a superficie sem alterar a sua frequencia. Assim, BRDFs encapsulam as propriedades de reflexão de um material levando em conta vários fatores, como rugosidade da superfície, ângulo de incidência, angulo de reflexão
Formalmente uma BRDF pode ser definida por $F(w_i, w_o)$, onde $w_i$ é a direção indicente de luz e $w_o$ é a direção de saída.

Para BRDFs fisicamente realistas algumas propriedades devem ser respeitadas.

\begin{itemize}
  \item A propriedade de positividade, $ F(\omega_i, \omega_o) \geq 0 $, que garante não existência de energia negativa. 

  \item Também, deve-se obedecer a reciprocidade de Helmhotz, $F(\omega_i, \omega_o) = F(\omega_o, \omega_i)$. Essa reciprocidade é usado na renderização, pois no lugar de traçar os raios da fonte de luz até a camera, podemos traçar os raios da camera até a fonte de luz otimizando a maior parte dos raios traçados diretamente da fonte de luz que não iriam antigir a lente da camera, exitando desperdicio de poder computacional em raios que não contribuem para intensidade de um dado pixel.

  \item A BRDF deve, também, respeitar a conversação de energia, $\forall  \omega_i, \int_{H^2}{F(\omega_i, \omega_o)cos(\theta_o) d\omega_o}\leq 1$. Nesse caso parte da energia pode ser absorvida, ou seja, transformado em outra forma de energia como calor, nesse caso esse somatório infintesimal pode no máximo chegar a 1, mas nunca ultrapassar.
\end{itemize}

\section{BRDF Models} \label{brdfmodels}


\subsection{Superfície Pura Especular}
Uma superfície puramente especular reflete a luz apenas em uma direção, seguindo a lei da reflexão. Ela produz reflexões nítidas, semelhantes a espelhos.
A BRDF para uma superfície puramente especular é frequentemente representada pela função delta de Dirac $\delta(\omega_i - \omega_o)$, onde $\omega_i$ é a direção da luz incidente e $\omega_o$ é a direção refletida.
$f(\omega_i, \omega_o) = k_s \cdot \delta(\omega_i - \omega_o)$
A função delta de Dirac garante que toda a luz incidente seja refletida na direção perfeitamente espelhada, resultando em uma reflexão altamente focada e intensa. Esse tipo de superfície é comum em materiais como metal polido ou vidro.

\subsection{BRDF Difusa Ideal}
Uma BRDFs difusa ideal reflete a luz incidente uniformemente em todas as direções, sem preferência por ângulos específicos. é representada por um termo cosseno lambertiano $\frac{\rho_d}{\pi} \cdot \cos \theta$, onde $\rho_d$ é o albedo da superfície e $\theta$ é o ângulo entre a direção da luz incidente e a normal da superfície.
$f(\omega_i, \omega_o) = \frac{\rho_d}{\pi} \cdot \cos \theta$
O termo cosseno garante que a radiância refletida seja proporcional ao cosseno do ângulo entre a direção da luz incidente e a normal da superfície. Esse modelo pode representar superfícies como tinta fosca ou papel.

\subsubsection{BRDF Brilhante (\textit{Glossy})}
Uma superfície brilhante exibe propriedades de reflexão tanto especulares quanto difusas. BRDF para uma superfície brilhante é frequentemente representada por uma combinação de termos especulares e difusos, como o modelo de Blinn-Phong @ref

\subsubsection{BRDF Retro-Refletora}
Uma superfície retro-refletora reflete a luz incidente de volta na direção de onde veio, independentemente do ângulo de incidência. A BRDF para uma superfície retro-refletora envolve tipicamente geometria especializada ou revestimentos projetados para redirecionar a luz de volta para a fonte.

\section{Compiladores} \label{compiladores}

\subsection{Cadeia de Símbolos e Alfabeto} \label{simbolos}

Um \textbf{cadeia de símbolos} é uma sequência finita de símbolos retirados de um alfabeto $ \Sigma $. Formalmente, um cadeia $ w $ é representado como $ [w_1, w_2, ..., w_n] $, onde cada $ w_i $ pertence ao alfabeto $ \Sigma $. O \textbf{alfabeto} $ \Sigma $ é um conjunto finito de símbolos distintos usados para construir cadeias em uma linguagem. Ele define os blocos de construção a partir dos quais cadeias válidas na linguagem são formadas.

\subsection{Definições de Linguagens} \label{linguagem}

Na ciência da computação, as linguagens são sistemas formais compostos por símbolos e regras que são muito uteis para definir um significado algoritimico. Uma \textbf{linguagem} $L$ é definida como um conjunto de cadeias sobre um alfabeto finito $ \Sigma $, $ L \subseteq \Sigma^* $, onde  $ \Sigma^* $ denota o conjunto de todas as cadeias possíveis sobre $ \Sigma $. A estrutura e semântica de uma linguagem  inclue seu alfabeto $ \Sigma $, sintaxe e regras de gramática.

\subsection{Compilador como um Transformação}

Um compilador pode ser visto como um transformação entre linguagens $ L_1 $ e $ L_2 $ que preserva a estrutura interna dos cojuntos, isto é, deve manter o mesmo significado algoritmico. Assim, o compilador $ C: L_1 \rightarrow L_2 $ mapeia programas escritos na linguagem de origem $ L_1 $ para programas equivalentes na linguagem de destino $ L_2 $. Essa transformação garante a preservação semântica, mantendo o comportamento pretendido do programa original durante a tradução.


\subsection{Gramática} \label{gramatica}

Para auxiliar na criação de um compilador é necessario entender as regras que auxiliam na validação e geração da linguagem de interesse, esse entedimento pode ser alcaçando pela gramática. Uma gramática $ G $ é um sistema formal composto por um conjunto de regras de produção que especificam como cadeias válidas na linguagem podem ser geradas. Ela inclui terminais, não-terminais, regras de produção e um símbolo inicial.

\begin{itemize}
  \item Terminais: Terminais são os símbolos básicos a partir dos quais as cadeias são formadas. Eles representam as unidades elementares da sintaxe da linguagem.
  \item Não-terminais: Não-terminais são espaços reservados que podem ser substituídos por terminais ou outros não-terminais de acordo com as regras de produção.

  \item Regras de Produção: As regras de produção definem a transformação ou substituição de não-terminais em sequências de terminais e/ou não-terminais.

  \item Símbolo Inicial: O símbolo inicial é um não-terminal especial a partir do qual a derivação de cadeias válidas na linguagem começa.
\end{itemize}


\subsubsection{Gramáticas Livres de Contexto (GLCs)}

Um tipo comum de gramática usado na definição de linguagens é a gramática livre de contexto (GLC). Em uma GLC $ G=(V,\Sigma,R,S)$:

\begin{itemize}
  \item $V$ é um conjunto finito de símbolos não-terminais.

  \item $\Sigma$ é um conjunto finito de símbolos terminais disjunto de $V$.

  \item $R$ é um conjunto finito de regras de produção, cada regra no formato $A \rightarrow \beta$, onde $A$ é um não-terminal e $\beta$ é uma cadeia de terminais e não-terminais.

  \item $S$ é o símbolo inicial, que pertence a $V$.
\end{itemize}

O processo de gerar uma cadeia na linguagem definida por uma gramática é chamado de derivação. Isso envolve aplicar regras de produção sucessivamente, começando pelo símbolo inicial $S$ até restarem apenas símbolos terminais.

Uma árvore sintática é uma representação gráfica do processo de derivação, onde cada nó representa um símbolo na cadeia e cada aresta representa a aplicação de uma regra de produção, nos processos seguintes como análise sintatica,em código, essa árvore é gerada e usada como representação intermediária que auxilia na geração na linguagem alvo $L_2$.


\subsection{Análise Léxica}
A análise léxica, também conhecida como \textit{lexing} ou \textit{tokenization}, é a primeira etapa do processo de compilação, na qual a entrada textual é dividida em unidades léxicas significativas chamadas de \textit{tokens}. Esses tokens representam os componentes básicos da linguagem, como palavras-chave, identificadores, operadores e literais. O analisador léxico percorre o código fonte caractere por caractere, agrupando-os em tokens conforme regras pré-definidas pela gramática da linguagem. No caso a linguagem do entrada analisador léxico são os formados por caracteres e, geralmente, são reconhecivel por maquinas de estado @ref, já a linguagem de saída é composta por tokens.

\subsection{Análise Sintática ou \textit{Parsing}}
A análise sintática é a segunda fase do processo de compilação, na qual os tokens gerados pela análise léxica são organizados e verificados quanto à conformidade com a gramática da linguagem. Essa etapa envolve a construção de uma árvore sintática ou estrutura de dados equivalente que representa a estrutura hierárquica das expressões e instruções do programa. O analisador sintático utiliza regras de produção gramatical para validar a sintaxe do código fonte e identificar possíveis erros.

\subsection{Pratt Parsing}
O Pratt Parsing, introduzida por Vaughan Pratt, é uma técnica de análise sintática recursiva que permite analisar expressões com precedência de operadores de forma eficiente e sem ambiguidades. Uma das características distintivas do Pratt Parsing é a maneira como lida com a precedência dos operadores, que é determinada pela ordem de avaliação das expressões. Ao contrário da análise descendente recursiva tradicional, onde cada não-terminal possui uma função de análise, a análise Pratt associa funções de manipulação (handlers) com tokens. Essas funções de manipulação são responsáveis por analisar expressões envolvendo seus respectivos tokens.

\subsubsection{Precedência de Expressões}

Na implementação do Pratt Parser, a precedência das expressões é definida por meio de uma tabela de precedência, na qual cada operador é associado a um nível de precedência. Isso permite que o parser decida dinamicamente a ordem de avaliação das expressões com base nos operadores encontrados durante a análise.

Essa abordagem simplifica significativamente a implementação do parser e elimina a necessidade de criar uma grammática que encapsula a precendencia em sua definição, também evita recursão profunda para lidar com diferentes níveis de precedência, tornando o Pratt Parsing uma técnica eficiente para análise sintática.

\subsubsection{Árvores Inclinadas}

No Pratt \textit{Parsing}, a estrutura da árvore de expressão pode ser influenciada pela ordem de avaliação dos operadores. Essa distinção leva a dois tipos de árvores de expressão: árvores inclinadas à direita e árvores inclinadas à esquerda.

\textbf{Árvore inclinada à Direita:} Em uma árvore inclinada à direita, operadores com maior precedência são resolvidos primeiro, mesmo que apareçam mais tarde (para a direita) na expressão. Isso resulta em uma árvore onde os operadores com maior precedência estão mais próximos da raiz, indicando que eles são avaliados primeiro. Considere a expressão `1 + 2 * 3`. Apesar de `*` aparecer após `+`, ele tem uma precedência mais alta e, portanto, forma uma subárvore que é resolvida antes da adição. A árvore resultante é:


\begin{verbatim}
               +
              / \
             1   *
                / \
               2   3
\end{verbatim}

\textbf{Árvore inclinada à Esquerda:} Por outro lado, em uma árvore inclinada à esquerda, operadores com maior precedência são resolvidos por último, seguindo uma ordem de avaliação da esquerda para a direita. Isso significa que operadores com maior precedência formam subárvores que são resolvidas mais profundamente na árvore. As árvores inclinadas à esquerda estão tipicamente associadas a chamadas recursivas na análise.

Para alcançar a estrutura desejada da árvore, o Pratt parsing utiliza as estratégias de recursão e iteração com base na precedência dos operadores para saber o momento de gerar uma subarvores inclinada para esquerda ou direita. Operadores com precedência maior que a do operador atual formam a estrutura inclinada à direita, enquanto operadores com precedência menor formam a estrutura inclinada à esquerda.

\subsubsection{Pseudo-código para Análise de Expressões}

O pseudo-código \ref{alg1},
demonstra o Pratt \textit{parsing} para a construção de árvores de expressão, considerando tanto estruturas inclinadas à direita quanto à esquerda. Esse algoritmo também é robusto mesmo quando um operador é tanto infixo quanto prefixo, por exemplo "$-$" pode ser um \textit{token} de subtração ou de negação. Assim cada token tem uma função de prefixo e infixo associada.

Nesse algoritimo, 
\textbf{proximo\_token()} recupera o próximo elemento da lista de tokens,
\textbf{token.precedencia}() retorna a precedencia do token atual, \textbf{token.prefixo()} é a função associada ao token que realisa o parsing de uma expressão quando o token é o primeiro em uma subexpressão (e.g. o token "$-$" é o primeiro na expressão "$-3$"). Já o   
\textbf{token.infixo}(esquerda) é a função associada ao token uma função que cria um nó subárvore utilizando outra subarvore já criada como entrada para gerar expressão com operadores infixos, por exemplo a subarvore esquerda pode ser a expressão "$-3$", o token atual ser "$*$" e o o retorno gera a expressão completa "$-3 * 1$"

Tanto \textbf{token.infixo} quanto \textbf{token.prefixo} podem ser indiretamente recursivas, isto é, ambas podem chamar a função \textbf{expressao} no algortimo \ref{alg1}. 
Por fim, \textbf{precedencia\_anterior} representa a precedência do token anterior, garantindo que os operadores sejam resolvidos na ordem correta.

\begin{algoritmo}[H]
	\caption{Função Pratt Parsing de Expressão}
	\label{alg1}
  \begin{lstlisting}
  function expressao(precedencia_anterior:=0):
      token := proximo_token()
      esquerda := token.prefixo()
      while precedencia_anterior < token.precedencia():
          token    = proximo_token()
          esquerda = token.infixo(esquerda)
      return esquerda
  \end{lstlisting}
\end{algoritmo}

\subsection{Geração da Linguagem Alvo} \label{codegen}

Nesta fase, fazemos a transição da representação intermediária  da linguagem origem \( L_1 \)  para  a linguagem de destino \( L_2 \). O processo envolve traduzir construções da linguagem de origem \( L_1 \) em suas representações equivalentes na linguagem de destino \( L_2 \). Podemos realizar essa tradução ao percorrer recursivamente os nós da arvóre sintatica usando as informações contidas nesses nós para gerar partes do programa final em $L_2$.

Dado um programa $a \in L_1$ existem varios programas $b_{i=1,2,3,...} \in L_2$ que possui estrutura semanticamente equivalentes à $a$. Ao explorar esse conjunto, é possivel escolher um $b_j \in L_2$ tal que esse programa seja otimizado em algum sentido, como uso eficiente de memoria, ou executar menos instruções de \textit{hardware}. Nosso foco neste trabalho está na tradução semanticamente correta, sem envolver explorão das saídas  equivalentes.

Como exemplo, considere a tradução de um cálculo matemático de \( L_1 \) para \( L_2 \):

\[
 \quad \mathbf{v} = (\mathbf{a} + \mathbf{b}) \cdot \mathbf{c} - (\mathbf{d} \times \mathbf{e})
\]

Após a tradução da expressão matematica para \( L_2 \), o cálculo pode ser convertido para o trecho de programa abaixo. Esse código é válido na linguagem GLSL.

\[
\quad \text{{vec3 v = dot(a + b, c) - cross(d, e);}}
\]


\section{Introdução ao Shading e ao Pipeline de GPU} \label{shading}

Shading refere-se ao processo de determinar a cor e o brilho dos pixels em uma imagem renderizada. Isso envolve simular a interação da luz com as superfícies, levando em consideração as propriedades dos materiais, condições de iluminação e orientação da superfície. Isso é alcançado por meio de pequenos programas chamados shaders, que são compilados e executados na unidade de processamento gráfico (GPU).


A interação com as GPUs é facilitada por meio de uma 
(API), em portugues, Interface de Programação de Aplicação, sendo o OpenGL uma API padrão para o uso de funções na GPU. O OpenGL foi criado como um padrão de programação aberto e multiplataforma para GPUs. O pipeline de renderização do OpenGL é composto por várias etapas, incluindo definição de dados de vértices, shaders de vértice e fragmento, shaders de tesselação e geometria opcionais, configuração de primitivas, recorte, rasterização e shader de fragmento.

Essas etapas coordenam o fluxo de dados da CPU para a GPU e suas transformações, culminando na geração da imagem final. As etapas mais importantes para o nosso trabalho são o shading de fragmento e de vértice, os quais executam a manipulação dos vértices e determinar cores de pixels, respectivamente.

@image put in the overview image


\subsection{Vertex Shader}

O vertex shader opera em vértices individuais de primitivas geométricas antes de serem rasterizados em fragmentos. Sua principal tarefa é transformar vértices do espaço de coordenadas local do objeto para o espaço de coordenadas global da cena e passar os dados necessários para o fragment shader. Esses shaders geralmente realizam várias transformações nos dados dos vértices, permitindo que objetos sejam posicionados, orientados e projetados em uma tela 2D. Nesta seção, discutimos algumas das transformações comuns realizadas por shaders de vértice.

Ao fim dessa estapa, os vértices são normalizados para garantir coordenadas homogêneas. Coordenadas homogêneas são necessárias para realizar a projeção perspectiva e outros cálculos no pipeline de renderização.


\begin{verbatim}
// Exemplo de Shader de Vértice
#version 330 core

layout(location = 0) in vec3 inPosition;
layout(location = 1) in vec3 inNormal;

uniform mat4 modelViewProjection;

out vec3 fragNormal;

void main() {
    vec3 manipulatedPosition = inPosition + (sin(gl_VertexID * 0.1) * 0.1);
    fragNormal = inNormal;
    gl_Position = modelViewProjection * vec4(manipulatedPosition, 1.0);
}
\end{verbatim}

\subsection{Fragment Shader}

O Fragment Shader opera em fragmentos rasterizados produzidos pela etapa de rasterização. Sua principal responsabilidade é determinar a cor final de cada fragmento com base na iluminação, texturização e propriedades da superfície. O modelo mental é interpretar esse programa  sendo repetido para todos os pixeis da imagem paralelamente, e ainda, esse programa recebe dados interpolados, como vértices e normais, ou seja, cada instancia desse programa possue entradas diferentes uma das outras. Esses valores interpolados são calculados usando interpolação bariêntrica em toda a superfície da primitiva.

Neste shader é onde as BRDFs devem ser implementadas para atingir um nível de shading mais preciso, pois temos mais dados do que os passados, devido à interpolação. Isso resulta em um nível de granularidade maior, considerando uma transição mais suave de um ponto para outro dentro de um triângulo.

@image{ put an image about verter shading and fragment shading}

\begin{verbatim}
// Exemplo de Shader de Fragmento
#version 330 core

in vec3 fragNormal;
out vec4 fragColor;

void main() {
    fragColor = vec4(1.0, 0.0, 0.0, 1.0); 
}
\end{verbatim}

\chapter{Revisão Bibliográfica} \label{revisao}

Para esta seção, será conduzida uma revisão literária abrangente com o objetivo de explorar trabalhos relacionados ao desenvolvimento de compiladores para tradução de BRDFs expressas em \LaTeX  para a linguagem de shading, empregando, técnicas de parsing. O processo de busca será conduzido em duas etapas distintas. Primeiramente, será realizado um levantamento dos trabalhos existentes nas bases de dados  com relevantes periodicos, anais de eventos, artigos e trabalhos. 


Por fim, será realizada uma busca por produtos ou ferramentas similares no mercado, utilizando strings de busca específicas em repositórios digitais, especificamente GitHub, e SourceForge. Esses processos de busca permitirão identificar referências relevantes e estabelecer um panorama do estado da arte no campo dos compiladores de BRDFs  para shaders, contribuindo para a compreensão do contexto acadêmico e prático no qual este trabalho se insere.

\section{Mapeamento Sistemático}

Com o intuito de obter resultados relevantes para a pesquisa, foram elaboradas frases de busca com base nos termos-chave relacionados ao tema deste trabalho. Assim como, foram criadas questões de pesquisa para guiar a seleção dos trabalhos.

\subsection{Seleção das Bases}
As bases escolhidas foram: ACM Digital Library,  IEEE Xplorer Digital Library,  Biblioteca Digital Brasileira de Teses e Dissertações (BDTD), Portal de Periódicos da CAPES,  Google Acadêmico, esse foram escolhidos por serem acessíveis gratuitamente pela afiliação à Universidade Federal de Sergipe, já o google scholar foi escolhido para agregar pesquisas em outras bases que possam ter trabalhos relevantes.

\url{https://bdtd.ibict.br/}
\url{https://ieeexplore.ieee.org/}
\url{https://www-periodicos-capes-gov-br.ezl.periodicos.capes.gov.br/}



\subsection{Questões de Pequisa} 

Foram elaboradas questões de pesquisa específicas, que guiam as frases-chave que refletem os principais aspectos do tema em questão. A partir desse processo, foram identificados e selecionados os trabalhos que melhor atendiam às questões propostas, garantindo maior relevância para o estudo em questão.

\begin{enumerate}
  \item Quais são as abordagens mais comuns utilizadas na criação de compiladores para tradução de BRDFs expressas em alguma linguagem de texto, com \LaTeX , para shaders?

  \item Quais as técnicas de parsing que têm sido aplicadas no desenvolvimento de compiladores para linguagens matemáticas como \LaTeX ?

  \item O trabalho utiliza arvores, ou gramáticas livre de contexto para representar uma BRDF?

 \item Quais são os principais desafios enfrentados ao traduzir funções matemáticas complexas, como as BRDFs, em shaders?

 \item Quais são as ferramentas e recursos disponíveis para auxiliar no desenvolvimento de compiladores para BRDFs e shaders, e como elas podem ser integradas ao processo de desenvolvimento?

\end{enumerate}



\subsection{Termos de Busca}
 As frases foram contruidas considerando suas variações equivalentes através de operadores lógicos. Posteriormente, as frases de pesquisa foram adaptadas de acordo com as características individuais de cada base de dados utilizada nas pesquisas. Os termos-chave escolhidos foram: "shader", "BRDF", "compiler", "parser" e "grammar".


\begin{table}[H]
\ABNTEXfontereduzida
\caption[bases]{}
\label{tab-bases}
\begin{tabular}{p{2.6cm}|p{6.0cm}|p{2.25cm}|p{3.40cm}}
  %\hline
   \textbf{Bases} & \textbf{Termos de Pesquisa}  & \textbf{Resultados}\\
   \hline
    IEEE Xplore Digital Library
    &
    ("Full Text \& Metadata":brdf)
AND (("Full Text \& Metadata":shader) OR  ("Full Text \& Metadata":shading))
AND (("Full Text \& Metadata":compiler) OR  ("Full Text \& Metadata":parsing) OR  ("Full Text \& Metadata":parser) OR  ("Full Text \& Metadata":grammar))
   & 36
    \\ \hline

    BDTD
    & (Todos os campos:compiler OU Todos os campos:parsing OU Todos os campos:parser OU Todos os campos:compilador) E (Todos os campos:shader OU Todos os campos:shading) E (Todos os campos:brdf)
    & 0
    \\ \hline
    CAPES Periodico
    &  Qualquer campo contém brdf E 
 Qualquer campo contém compi* E shad*  
    & 0
    \\ \hline

  ACM Digital Library
  & AllField:((shader OR shading) AND brdf AND (compiler OR compiling) AND (parser OR grammar OR parsing))
  & 46
    \\ \hline

 Google Academico 
  & 
  ("BRDF" AND ("COMPILER" OR "COMPILING") AND( "PARSER" OR "PARSING") AND ("SHADER" OR "SHADING"))
  & 69
   % \hline
\end{tabular}
% \legend{Fonte: \citeonline{van86}}
\end{table}

\subsection{Critérios}

Para garantir relevancia dos resultados obtivos, seguimos os critérios de inclusão e exclusão estabelecidos, de forma que os resultados serão filtrados. Ao fim desse procedimento, apenas os resultados com maior compatibilidade com este trabalho seram análisado e descritos de maneira mais detalhada.

\subsubsection{Critérios de Inclusão}

\begin{enumerate}
  \item Foram incluídos artigos relacionados às palavras-chaves;
  \item Foram incluídos artigos que de alguma forma inclua a criação de um compilador ou um parser;
  \item Foram incluídos artigos que sintetize uma arvóre como representação de BRDFs
\end{enumerate}

\subsubsection{Critérios de Exclusão}

\begin{enumerate}
  \item Foram excluídos artigos dos quais dispunham de links incorretos e ou quebrados;
  \item Foram excluídos artigos que dispunham de aplicacões muito similares/repetitivas;
  \item Foram excluídos artigos que não respodem as questões de pesquisa \ref{sec:questoes-pesquisa};
  \item Artigo que não tem como entrada a BRDFs no formato de equação, ou seja, está utilizando a representação diretamente como código, também foi excluído.
  \item Foram excluídos artigos que não consideram a geração de shaders como saída ou estrutura da BRDF em arvore.
  \item Foram excluídos artigos que não citam BRDFs e compilador em seu resumo;
  \item Se após a leitura completa, o artigo não concerne os interesse deste trabalho, esse foi excluído.
\end{enumerate}


\begin{table}[H]
\ABNTEXfontereduzida
  \caption[bases]{Resultados da Base após aplicar os critérios}
\label{tab-bases}
\begin{tabular}{p{6.6cm}|p{6.6cm}}
  %\hline
   \textbf{Bases}  & \textbf{Filtrados}\\
   \hline
    IEEE Xplore Digital Library
   & 2
    \\ \hline
    BDTD
    & 0
    \\ \hline
    CAPES Periodico
    & 0
    \\ \hline

  ACM Digital Library
  & 1
    \\ \hline
 Google Academico 
  & 1
   % \hline
\end{tabular}
% \legend{Fonte: \citeonline{van86}}
\end{table}



\subsection{Descrição dos Trabalhos Relacionados}

\subsubsection{genBRDF: Discovering New Analytic BRDFs with Genetic Programming}

Neste artigo é introduzido uma framework chamada genBRDF, a qual aplica tecnicas de programação genética para explorar e descobrir novas BRDFs de maneira analitica. O processo inicia utilizando uma BRDF existente, e iterativamente aplica mutações e recombinações de partes das expressões matematicas que compões essas BRDFs a medida que novas gerações surgem. Essas mutações são guiadas por uma função fitness, que seria o inverso de uma função de erro, essa é baseada em um dataset de materiais já medidos. Por meio da avaliação de milhares de expressões, a framework identificas as viávies, que estão na Fronteira de Pareto.

A representação das BRDFs de entrada para o GA, autores geraram uma gramática que inclui constantes e operadores matemáticos comuns encontrados em equações BRDF. A gramática é compilada, e a árvore de sintaxe abstrata resultante passa por modificações realizadas pelo algoritmo genético. Nós na árvore podem ser trocados, substituídos, removidos e novos nós podem ser adicionados. Esse processo, após refinamento e análise, resulta em novas BRDFs.

Alguns dos novos modelos BRDF apresentados no documento incluem aqueles que superam os modelos existentes em termos de precisão e simplicidade.
 
Esse artigo se concentra principalmente em utilizar programação genética para descobrir automaticamente novos modelos analíticos de BRDF, em vez de compilar diretamente equações BRDF em linguagens de shading. Embora a representação das expressões das BRDFs possam potencialmente inspirar o nosso trabalho, o principal objetivo do artigo difere do objetivo de compilar equações BRDF para linguagem de shading.

\subsubsection{Slang: language mechanisms for extensible real-time shading systems}

O artigo descreve a linguagem Slang, uma extensão da amplamente utilizada linguagem de shading HLSL, projetada para melhorar o suporte à modularidade e extensibilidade. A abordagem de design da Slang é baseada em dois princípios fundamentais: manter a compatibilidade com o HLSL existente sempre que possível e introduzir recursos com precedentes em linguagens de programação mainstream para facilitar a familiaridade e intuição dos desenvolvedores.

O autor destaca que cada extensão da Slang visa fornecer uma trajetória incremental para a adoção a partir do código HLSL existente, evitando a necessidade de uma migração completa. Algumas dessas extensões são: funções generica, struct genericas, tipos que implementam uma dada interface assim como interfaces funcionam em Java nas para struct.
Exemplo de funçao generica escrita em Slang:

\begin{verbatim}
float3 integrateSingleRay<B:IBxDF>(B bxdf,
SurfaceGeometry geom, float3 wi, float3 wo, float3 Li)
{ return bxdf.eval(wo, wi) * Li * max(0, dot(wi, geom.n)); }

\end{verbatim}


Enquanto o artigo se concentra na extensão de linguagens de shading existentes para melhorar a eficiência e a extensibilidade dos sistemas de shading em tempo real, o nosso trabalho se concentra na compilação de equações BRDF em linguagens de shading para explorar e descobrir novos modelos analíticos, mesmo para pessoas que não tem o conhecimento ténico da linguagem de shading espeficica. Embora ambos os projetos façam uso de shading e compilação, as abordagens e focos são diferentes.

\subsubsection{Tree-Structured Shading Decomposition}

O artigo propõe uma abordagem para inferir uma representação de BRDF estruturada em árvore a partir de uma única imagem para a sombreamento de objetos. Em vez de usar representações paramétricas ou medidas para modelar o sombreamento, como é comum, é proposta uma abordagem que utiliza uma representação em árvore de shading, combinando nós de sombreamento básicos e métodos de composição para decompor o sombreamento da superfície do objeto.

Essa representação permite que usuários inexperientes editem o sombreamento do objeto de maneira eficiente e intuitiva. Para abordar o desafio de inferir a árvore de sombreamento, é proposta uma abordagem híbrida que combina um modelo de inferência auto-regressivo para gerar uma estimativa aproximada da estrutura da árvore com um algoritmo de otimização para ajustar a árvore inferida. Experimentos são realizados em diversas imagens para demonstrar a eficácia da abordagem proposta.

\begin{figure}[H]
	\caption{\label{fig_grafico} Exemplo de decomposição de BRDFs em nós de uma arvóre}
	\begin{center}
	    \includegraphics[scale=0.5]{./Imagens/tree-shading.png}
	\end{center}
	\legend{Fonte: \citeonline[p. 24]{lol}}
\end{figure}


Assim como o nosso trabalho, esse artigo se concentra em facilitar o processo para usuários inexperientes, pois ambos visam fornecer ferramentas acessíveis para manipular representações de sombreamento sem exigir conhecimento avançado em programação de shading. Esse artigo também emprega uma representação em árvore, embora para um propósito diferente. Enquanto o nosso trabalho utiliza árvores para representar expressões matemáticas de BRDFs, esse artigo utiliza a decomposição em nós de árvores para representar o shading parcial de objetos.

\subsubsection{A Real-Time Configurable Shader Based on Lookup Tables}



Este trabalho propõe uma arquitetura de hardware que permite cálculos de shading por pixel em tempo real, utilizando lookup-tables. Para isso, são projetados circuitos configurável baseado em lookup-tables, memórias de acesso aleatório (RAMs) e memórias somente leitura (ROMs). Varios circuitos base foram projetados visando realizar cálculos de shading, considerando as operações mais comuns, por exemplo, circuitos para calcular produto interno entre dois vetores, circuitos de rotação de um vetor por um angulo. Ademais, é usado interpolação em um sistema de coordenadas polares em vez da interpolação vetorial convencional com normalização, com o objetivo de reduzir o tamanho dos circuitos e melhorar o desempenho.


\begin{figure}[H]
	\caption{\label{fig_grafico} Exemplo de circuito de produto interno entre vetores}
	\begin{center}
	    \includegraphics[scale=0.9]{./Imagens/rom-cos-lookup-table.png}
	\end{center}
	\legend{Fonte: \citeonline[p. 24]{lol}}
\end{figure}


Além disso, o circuito suporta diversas BRDFs, como Blinn-Phong, Cook-Torrance, Ward e modelos baseados em microfacetes, com tabelas de lookup específicas para cada modelo. O uso de tabelas de pesquisa permite a representação organizada da parametrização das BRDFs, tornando o processo de transformação de BRDF para shaders mais acessível. Assim como este trabalho, a abordagem facilita a geração de shaders a partir da descrição de BRDFs, apesar da metologia ser diferente.

\section{Pesquisa por Repositórios online}
Também foram analisados repositórios no github e SourceForge, cada um com uma string de busca especifica. Os repositórios encontrados foram filtrados baseados em seus resumos, caso não haja a menção da criação de um compilador, ou não citar uma transformação de BRDF para outra estrutura, esse repositório será excluido.


\begin{table}[H]
\ABNTEXfontereduzida
\caption[bases]{}
\label{tab-bases}
\begin{tabular}{p{2.6cm}|p{6.0cm}|p{2.25cm}|p{3.40cm}}
  %\hline
   \textbf{Plataformas} & \textbf{Termos de Pesquisa}  & \textbf{Resultados}\\
   \hline
   GitHub
   &
   in:readme (GLSL AND BRDF AND  (compiler OR compilation) AND (shader OR shading))
   & 15
   \\ \hline
   SourceForge
   &
   compiler bdrf
   & 0
\end{tabular}
% \legend{Fonte: \citeonline{van86}}
\end{table}


Após ler por completo os resumos dos repostiórios do GitHub, é evidente que nenhum desses projetos é relacionado com o proposto neste trabalhos, apesar de comentar sobre BRDFs, esses projetos não implementam compiladores, não fazem parsing de equações de BRDFs e nem mesmo geram shaders a partir de BRDFs.

\chapter{Metodologia} \label{metodologia}

A metodologia para desenvolver o compilador proposto envolve uma abordagem sistemática composta por etapas adaptadas para alcançar os objetivos de pesquisa especificados. Essas etapas incluem uma análise aprofundada das informações relacionadas pertinentes a BRDFs e compilação de shaders, exploração de técnicas existentes dentro do domínio, formulação de especificações de linguagem precisas, design e execução meticulosos de casos de teste abrangentes, a implementação real do compilador e a avaliação de seu desempenho por meio de experimentos de renderização.


\section{Análise Abrangente} \label{analise}

O primeiro passo envolve a realização de uma análise detalhada das áreas relacionadas ao desenvolvimento da ferramenta proposta. Isso inclui a revisão da literatura sobre BRDFs, linguagens de shaders, design de compiladores e técnicas de renderização gráfica. Isso envolve o estudo de artigos de pesquisa, ferramentas existentes e bibliotecas de software relevantes para identificar técnicas existentes e áreas potenciais para melhoria.



\section{Especificação da Linguagem}

As especificações da linguagem de entrada e saída para o compilador são definidas. A linguagem de entrada é uma versão simplificada do \LaTeX , onde expressões matemáticas nos ambientes \texttt{equation} ou \texttt{align} são suficientes para os propósitos deste trabalho. O \LaTeX  é um sistema de composição amplamente utilizado para documentos matemáticos e científicos. Para descrever BRDFs usando equações \LaTeX , enquanto a linguagem de saída especifica a linguagem de shader GLSL para renderização.

Para a linguagem de entrada, optamos por usar o ambiente \texttt{equation} devido à sua simplicidade e uso generalizado na representação de expressões matemáticas. No \LaTeX , os ambientes fornecem uma maneira de agrupar e formatar texto ou equações. O ambiente \texttt{equation} é especificamente projetado para exibir equações individuais. Abaixo está um exemplo de código \LaTeX  usando o ambiente \texttt{equation}:

\begin{verbatim}
\begin{equation}
    f(x) = ax^2 + bx + c
\end{equation}
\end{verbatim}

Este código \LaTeX  representa uma equação quadrática \( f(x) = ax^2 + bx + c \), onde \( a \), \( b \) e \( c \) são coeficientes.

Quanto à linguagem de saída, ela especifica a linguagem de shader GLSL para renderização. Um exemplo de código de shader GLSL correspondente gerado a partir da equação \LaTeX  acima pode ser:

\begin{verbatim}
float quadratic(float x, float a, float b, float c) {
    return a * x * x + b * x + c;
}
\end{verbatim}

\section{Design de Casos de Teste} \label{testes}



Os casos de teste devem ser projetados para validar a correção e precisão do processo de tradução do compilador. Esses casos de teste emparelham equações \LaTeX  de entrada descrevendo BRDFs com o código de shader GLSL de saída esperado. Um caso específico que demonstra a capacidade do compilador pode ser criado com o BRDF de Cook-Torrance. A definição \LaTeX  e a saída esperada podem ser fornecidas como exemplo

\textbf{LaTeX Input (Cook-Torrance BRDF):}
\begin{verbatim}
\begin{equation}
f_{\text{CT}}(\omega_i, \omega_o) = \frac{D(h)F(\omega_i, h)G(\omega_i, \omega_o, h)}{4(\omega_i \cdot n)(\omega_o \cdot n)}
\end{equation}
\end{verbatim}

\textbf{GLSL Output esperado:}
\begin{verbatim}
float CookTorrance(vec3 normal, vec3 viewDir, vec3 lightDir, float roughness, float F0) {
    // halfway vector
    vec3 halfwayDir = normalize(viewDir + lightDir);

    // microfacet distribution function
    float D = ...; // D(h)

    // Calculate Fresnel term
    float F = ...; //F(wi, h) 

    // Calculate geometric attenuation factor
    float G = ...; //G(wi, wo, h)

    float denominator = 4.0 * max(dot(viewDir, normal), 0.0) * max(dot(lightDir, normal), 0.0);

    // Final BRDF value
    return (D * F * G) / denominator;
}
\end{verbatim}

\section{Implementação do Compilador} \label{compiladorimplementacao}

A implementação do compilador é feita usando a linguagem de programação Odin, escolhida por suas capacidades de linguagem de baixo nível com herança de composição e uma biblioteca padrão satisfatória. Técnicas de análise recursiva são utilizadas, especificamente o Parsing de Pratt, para processar as equações \LaTeX  de entrada e gerar o código de shader GLSL correspondente. Inicialmente, um lexer e um parser foram implementados para uma linguagem mais simples do que o \LaTeX  para garantir que os fundamentos do compilador sejam funcionais, com precedência totalmente testada para a árvore de sintaxe e também a execução disso.

\section{Experimentos de Renderização}

Por fim, experimentos de renderização são realizados usando os shaders gerados pelo compilador. Isso permite a avaliação do desempenho e da qualidade visual das imagens renderizadas produzidas pelos shaders compilados. A plataforma escolhida para os testes é a ferramenta Disney BRDF, compilada localmente para modificar e adicionar shaders adicionais. Ele fornece uma interface para definir parâmetros que servem como controles deslizantes para os hiperparâmetros do BRDF.

@ Imagem para a ferramenta
@ Código para o superconjunto GLSL

Seguindo esta metodologia, a ferramenta proposta visa compilar efetivamente descrições de BRDF em shaders GLSL, facilitando a geração de gráficos realistas em aplicativos de gráficos por computador.

\section{Plano de Continuação} \label{continuacao}

A continuação desta tese envolve várias tarefas-chave destinadas a completar o desenvolvimento do compilador proposto para converter equações \LaTeX  que descrevem BRDFs em código de shader GLSL. As tarefas incluem atualizar o lexer e o parser escritos em Odin para aceitar equações \LaTeX , testar o lexer e o parser para garantir o reconhecimento correto dos tokens \LaTeX  Math, testar o parser para garantir a árvore de sintaxe com a precedência correta, definir símbolos predefinidos como constantes matemáticas e outras quantidades, implementar o processo de geração de código GLSL usando a árvore de sintaxe usando o padrão de visitante @ref, expandir os casos de teste para cobrir uma melhor variedade de BRDFs, testar minuciosamente o código gerado quanto à correção e eficácia, incluindo as visualizações dos mencionados BRDFs em algumas cenas, preparar a apresentação final e, finalmente, escrever o documento do trabalho (TCC).

\begin{enumerate}
\item 06/05/2024 - 20/05/2024: Atualizar o lexer e o parser para aceitar equações \LaTeX .
\item 06/05/2024 - 27/05/2024: Testar o lexer para garantir o reconhecimento correto de todos os tokens \LaTeX  Math.
\item 06/05/2024 - 27/05/2024: Testar o parser para garantir a árvore de sintaxe com a precedência correta.
\item 13/05/2024 - 03/06/2024: Definir símbolos predefinidos como constantes matemáticas e outras quantidades.
\item 20/05/2024 - 10/06/2024: Implementar o processo de geração de código GLSL.
\item 27/05/2024 - 17/06/2024: Expandir os casos de teste para cobrir uma ampla gama de BRDFs.
\item 03/06/2024 - 24/06/2024: Testar minuciosamente o código gerado quanto à correção e eficácia, tanto em código quanto em visualização.
\item 17/06/2024 - 06/09/2024: Escrever o documento da tese.
\item 10/06/2024 - 01/07/2024: Preparar a apresentação final.
\end{enumerate}


\begin{adjustwidth}{-1.3cm}{-1cm}

\begin{ganttchart}[
vgrid,
hgrid,
x unit=1.01mm,
time slot format=isodate,
bar label font=\footnotesize,
group label font=\footnotesize,
milestone label font=\footnotesize,
]{2024-05-06}{2024-09-06}
    \gantttitlecalendar{year, month=shortname} \\
    \ganttbar{1. Atualizar lexer e parser}{2024-05-06}{2024-05-10} \\
    \ganttbar{2. Testar lexer para todos os tokens}{2024-05-10}{2024-05-15} \\
    \ganttbar{3. Testar parser para precedência}{2024-05-15}{2024-05-20} \\
    \ganttbar{4. Definir símbolos matemáticos}{2024-05-20}{2024-05-25} \\
    \ganttbar{5. Implementar geração de GLSL}{2024-05-25}{2024-06-01} \\
    \ganttbar{6. Expandir casos de teste para GLSL}{2024-06-01}{2024-06-10} \\
    \ganttbar{7. Testar correção do código}{2024-06-10}{2024-07-01} \\
    \ganttbar{8. Escrita do trabalho}{2024-06-01}{2024-08-25} \\
    \ganttbar{9. Preparar apresentação final}{2024-08-25}{2024-09-06}
\end{ganttchart}

\end{adjustwidth}


\chapter{Resultados Iniciais}
\label{resultadosiniciais}

\section{Parser and Lexer in Odin}\label{parser}

We built a lexer, parser and interpreter for a  simple language along with its grammar using Pratt parsing in Odin programming language, the repository can be found here \url{https://github.com/evertonse/pratt-parser}. The Pratt parser, is a recursive descente parser that means that each production rule as a associated parsing function. The implementation prioritizes simplicity and clarity, with extensive comments to aid understanding, specailly because it is meant to validate the parser for a ramp up, when we'll need to change to \LaTeX  tokens and de BRDF semantic meaning.

\subsection{Parser}

The Pratt parser, implemented in the `parser.odin` file, employs precedence climbing to efficiently handle arbitrary operator precedence levels. Unlike traditional recursive descent parsers, which often require multiple nested function calls for each precedence level, the Pratt parser organizes parsing functions hierarchically based on operator precedence.



\begin{algoritmo}[H]
  \caption{Parte principal do parsing de expressão em código Odin, nessa implementação usamos a notação original de @ref(pratt) null\_denotations and left\_denotations que o mesmo que funções de parsing para operadore prefix e infixo respectivamente}
	\label{alg1}
	\label{alg1}
  \begin{lstlisting}

parse_expr :: proc(prec_prev: i64) -> ^Expr {
    /* expressions that takes nothing (null) as left operand */
    left := parse_null_denotations() 
    /*
    . if current token is left associative or current token has higher precedence
    . than previous precedence then stay in the loop, effectively creating a left leaning
    . sub-tree, else, we recurse to create a right leaning sub-tree.
    */
    for precedence(peek()) > prec_prev + associativity(peek())  {
        /* expressions that needs a left operand such as postfix, mixfix, and infix operator */
        left = parse_left_denotations(left)
    }
    return left
}

  \end{lstlisting}
\end{algoritmo}

Functions such as `associativity` and `precedence` provide the necessary information for parsing operators correctly, ensuring the desired behavior in expressions.

@img(folder struture)
\subsection{Gramática}

A gramática é definida abaixo. Utilizamos uma notação leve de sintaxe para descrevê-la, todas as palavras em minúsculas são regras, o símbolo $*$ significa zero ou mais ocorrências, $()$ indica agrupamento para aplicar um operador a ele, $|$ é o operador ou, palavras entre aspas simples $''$ significam literalmente um token com esse conteúdo como caractere, e todas as letras maiúsculas representam um token que pode ter conteúdo diferente, mas possui o mesmo significado semântico. Por exemplo, NUMBER pode ser 2.0 ou 1.0, mas nas regras de produção eles são tratados da mesma forma. O símbolo $=$ indica uma produção.

\begin{verbatim}
start = assign* expr ;

expr = prefix expr 
       | expr postfix  
       | expr infix expr 
       | expr '?' expr ':' expr
       | call
       | NUMBER
       | IDENTIFIER
       ;

assign = IDENTIFIER '=' expr ';'
         | IDENTIFIER '=' 'fn' (' params ')' expr ';'
         ; 

call = expr '(' args ')';
args = expr
        | expr ',' args
        | 
        ;
params = IDENTIFIER
         | IDENTIFIER ',' params
         | 
        ;

postfix = '+' | '-' | '~' | '!';
prefix  = '+' | '-' | '~' | '!';
infix   = '+' | '-' | '*' | '/' | '^'
            | 'eq' | 'lt' | 'gt' | 'or' | 'and'
            ;

\end{verbatim}

Essa gramática define regras para expressões, atribuições, chamadas de função e vários operadores, como postfix, prefix e infix com o intuito de criar uma vasta coleção de operadores com diferentes precendecias para facilitar quando for transicionado para sintaxe \LaTeX .


\begin{algoritmo}[H]
	\caption{Exemplo código da linguagem implementada}
	\label{alg1}
	\label{alg1}
  \begin{lstlisting}[language = python]
    epsilon = 0.001; # proximidade em float

    abs = fn(a) a lt 0 or a lt -0 ? -a : a;

    float_close = fn(a, b) 
        abs(a - b) lt epsilon ? 
            1 : 0;

    # Classical fibonacci
    fib = fn(n)  
        float_close(n, 0) ? 
            0
        :float_close(n, 1) ?
            1
        :fib(n-1)  + fib(n-2);

    fib(10)  # Ultima expressao significa retorno do main
  \end{lstlisting}
\end{algoritmo}

\begin{algorithm}[H]
\begin{lstlisting}[language = python]
  cos = fn(a) a!; # Postfix '!' significa cosseno
  sin = fn(a) !a; # Prefixo '!' significa seno
  tan = fn(a) sin(a)/cos(a); # Temos acesso a procedimentos no escopo externo
  val = tan(98);
  val
\end{lstlisting}
\end{algorithm}

\subsection{Tabela de Símbolos}

Nesse projeto também foi desenvolvido uma tabela de símbolos simples, que será reaproveitado na análise semântica e na geração de código GLSL futuramente. A

A implementação da tabela de símbolos fornecida aqui é baseada em uma estrutura de escopo hierárquico, onde cada escopo mantém um mapeamento entre os nomes dos símbolos e seus atributos correspondentes. A estrutura \texttt{Scope} representa um mapeamento de nomes de símbolos para objetos de símbolo dentro de um \textbf{único} escopo, enquanto a \texttt{Scope\_Table} mantém uma pilha de escopos, permitindo aninhamento.

\subsubsection{Estrutura de Símbolos}

Cada símbolo na tabela de símbolos é representado pela estrutura \texttt{Symbol}, que contém os seguintes atributos:
\begin{itemize}
    \item \texttt{name}: O nome do símbolo.
    \item \texttt{val}: O valor associado ao símbolo (para variáveis).
    \item \texttt{is\_function}: Um sinalizador booleano indicando se o símbolo é uma função.
    \item \texttt{params}: Uma lista de tokens representando os parâmetros da função (se aplicável).
    \item \texttt{body}: Um ponteiro para a expressão que representa o corpo da função (se aplicável).
\end{itemize}

\begin{lstlisting}

Scope :: #type map[string]Symbol
Scope\_Table :: [dynamic]Scope

Symbol :: struct  {
    name : string,
    val: f64,
    is\_function: bool,
    params: []Token,
    body: ^Expr,
}

\end{lstlisting}

\subsubsection{Gerenciamento de Escopo}

A tabela de símbolos fornece funções para gerenciar escopos, incluindo:
\begin{itemize}
    \item \texttt{scope\_enter}: Entra em um novo escopo, anexando-o à pilha de escopos.
    \item \texttt{scope\_exit}: Sai do escopo atual, removendo-o da pilha de escopos e retornando-o.
    \item \texttt{scope\_reset}: Redefine a tabela de símbolos limpando todos os escopos.
    \item \texttt{scope\_get}: Recupera um símbolo da tabela de símbolos pelo seu identificador.
    \item \texttt{scope\_add}: Adiciona um novo símbolo ao escopo atual.
\end{itemize}


Essa tabela de símbolos será apdatada para a fase de geração de código e tradução adequada do código-fonte em shaders GLSL.


\subsubsection{Estrutura da Árvore de Sintaxe}

\begin{itemize}
\item \textbf{Ast}: A estrutura base para todos os nós da AST.
\item \textbf{Start}: Representa o ponto de partida do programa, contendo uma sequência de atribuições seguida de uma expressão.
\item \textbf{Assign}: Representa atribuições de variáveis, incluindo um identificador, operador de atribuição e expressão.
\item \textbf{Assign\_Function}: Estende Assign e representa definições de funções, incluindo parâmetros.
\item \textbf{Expr}: Representa expressões, servindo como a estrutura base para diferentes tipos de expressões.
\item \textbf{Expr\_Identifier}: Representa identificadores dentro de expressões.
\item \textbf{Expr\_Number}: Representa literais numéricos dentro de expressões.
\item \textbf{Expr\_Grouped}: Representa expressões agrupadas dentro de parênteses.
\item \textbf{Expr\_Prefix}: Representa operações unárias de prefixo.
\item \textbf{Expr\_Infix}: Representa operações binárias de infixo.
\item \textbf{Expr\_Postfix}: Representa operações unárias de sufixo.
\item \textbf{Expr\_Mixfix}: Representa operações ternárias de mixfix.
\item \textbf{Expr\_Function\_Call}: Representa chamadas de função com argumentos.

\end{itemize}

\subsection{Implementação do Padrão de Visitante}

O padrão visitante @ref foi empregado para percorrer e operar em uma árvore de sintaxe abstrata (AST). A estrutura da AST é definida com vários tipos de nó para capturar diferentes elementos da sintaxe.
Três procedimentos incorporam o padrão de visitante para percorrer e manipular a AST:

\begin{itemize}
  \item \textbf{walker\_interp}: Interpreta a AST, calculando o valor numérico das expressões.
  \item \textbf{walker\_paren}: Gera uma representação de string entre parênteses da AST, auxiliando na legibilidade e garantindo a ordem correta de avaliação.
  \item \textbf{walker\_print}: Imprime os nós da AST e seus atributos, facilitando a depuração e compreensão da estrutura da AST.
\end{itemize}

\subsection{Testing}
\subsection{Testes}

Para garantir a correção e robustez da implementação do parser de Pratt, foi desenvolvida uma ampla suíte de testes. Esses testes abrangem vários aspectos da funcionalidade do parser, incluindo geração de árvore de sintaxe, precedência de operadores e interpretação semântica.

\subsubsection{Geração de Árvore de Sintaxe}

Um aspecto crucial dos testes envolve verificar a correta geração de árvores de sintaxe a partir de expressões de entrada. Os testes são projetados para cobrir diferentes cenários, incluindo operações aritméticas simples, expressões complexas com subexpressões aninhadas e chamadas de funções.

Por exemplo, a suíte de testes de geração de árvore de sintaxe inclui casos para validar:

\begin{itemize}
    \item O manuseio correto de operadores unários e binários, garantindo a precedência e associatividade adequadas.
    \item A representação precisa de chamadas de função e seus argumentos dentro da árvore de sintaxe.
    \item O agrupamento adequado de expressões dentro de parênteses para impor regras de precedência.
\end{itemize}

\subsubsection{Precedência de Operadores e Associatividade}

Testes são conduzidos para validar a precedência e associatividade de operadores na gramática da linguagem. Isso inclui garantir que operadores com maior precedência sejam avaliados antes daqueles com menor precedência e que operadores associativos à esquerda ou à direita sejam analisados corretamente.

Exemplos de testes para precedência de operadores e associatividade incluem:

\begin{itemize}
    \item Verificar a correta parantezização de expressões envolvendo múltiplos operadores com níveis de precedência variados.
    \item Garantir que operadores unários sejam aplicados antes de operadores binários, de acordo com suas regras de precedência.
    \item Validar o agrupamento adequado de expressões para impor associatividade à esquerda ou à direita conforme especificado na gramática.
\end{itemize}

\subsubsection{Interpretação Semântica}

Além da geração de árvore de sintaxe e precedência de operadores, testes são realizados para garantir a interpretação semântica de expressões produza os resultados esperados. Isso envolve avaliar expressões e comparar a saída com os valores antecipados.

Por exemplo, os testes de interpretação semântica abrangem:

\begin{itemize}
    \item Avaliar expressões aritméticas envolvendo constantes, variáveis e chamadas de função para verificar resultados corretos.
    \item Verificar o comportamento de expressões condicionais (por exemplo, operador ternário) sob diferentes condições.
    \item Validar a correção das implementações de funções e seu comportamento dentro do ambiente de execução do parser.
\end{itemize}

Ao testar meticulosamente a geração de árvore de sintaxe, precedência de operadores e interpretação semântica, a implementação do parser de Pratt pode ser validada quanto à correção e confiabilidade, garantindo um desempenho robusto em vários cenários de entrada.
1. **Teste de Recursão**: Verifica a geração correta da sequência de Fibonacci até o 9º número. Por exemplo, verifica se o número de Fibonacci no índice 7 é calculado corretamente.

\begin{verbatim}
fib = fn(n)  
    float_close(n, 0) ? 
        0
    :float_close(n, 1) ?
        1
    :fib(n-1)  + fib(n-2);

fib(7)
\end{verbatim}

2. **Teste de Atribuição e Interpretação**: Avalia uma expressão envolvendo atribuições de variáveis e chamadas de função no mesmo escopo. Por exemplo, verifica se a função `val` calcula corretamente a subtração de seus argumentos.

\begin{verbatim}
a = 1;
b = 2;
c = 3;
d = 4;

val = fn(a,b,c,d) d-c-b-a; 
val(a,b,c,d, 2, 4 ,4)
\end{verbatim}

3. **Teste de Operador Relacional**: Verifica a precedência e associatividade dos operadores relacionais (`lt`, `gt`, `eq`) e lógicos (`or`, `and`). Por exemplo, verifica se a expressão `1 or 2 and 3 or 4` é corretamente parantezada.

\begin{verbatim}
1 or 2 and 3 or 4
\end{verbatim}

4. **Teste de Precedência de Operadores Unários e Binários**: Examina a precedência dos operadores unários e binários. Por exemplo, verifica se a expressão `!a + b` é corretamente interpretada com o operador unário `!` aplicado antes do binário `+`.

\begin{verbatim}
!a + b
\end{verbatim}

5. **Teste de Agrupamento**: Garante que as expressões entre parênteses sejam corretamente agrupadas. Por exemplo, verifica se a expressão `a + (b + c) + d` é parantezada conforme o esperado.

\begin{verbatim}
a + (b + c) + d
\end{verbatim}

Esses testes, junto com outros na suíte, ajudam a validar a correção da implementação do parser de Pratt, cobrindo várias características da linguagem e regras de precedência de operadores.


\section{\textit{Ray Tracing} }


Este capítulo apresenta o desenvolvimento e implementação de um simples \textit{ray tracer} usando métodos estocásticos de colisão de raios na linguagem de programação Odin com a biblioteca RayLib (\url{https://www.raylib.com/}) para renderização de imagens em uma janela. Isso foi feito para começar a entender melhor BRDFs e a equação de renderização.

O \textit{ray tracer} foi construído com instruções do livro \url{https://raytracing.github.io/books/RayTracingInOneWeekend.html}. Ele opera inteiramente na CPU, e a funcionalidade principal do \textit{ray tracer} envolve a modelagem de raios e sua reflexão dos pixels da imagem para a cena. A cena consiste exclusivamente de esferas, empregando cálculos de colisão padrão entre um raio e uma esfera.

\subsection{Implementação de Materiais}

O \textit{ray tracer} inclui vários materiais que ditam o comportamento dos raios ao interagir com superfícies, embora não garantidos de estar fisicamente vinculados, considerando a conservação de energia discutida no capítulo \ref{brdf}. Cada material é implementado como uma estrutura contendo um ponteiro de função de dispersão responsável por calcular a atenuação e o raio disperso após a interação com uma superfície. Os seguintes materiais são implementados:

\begin{itemize}
\item \textbf{Material Difuso}: Representa um material básico com refletância lambertiana.
\item \textbf{Material Lambertiano}: Uma variante do material difuso com albedo personalizável.
\item \textbf{Material Metálico}: Modela uma superfície metálica com reflexão especular, permitindo controle sobre a difusão.
\item \textbf{Material Dielétrico}: Simula materiais transparentes com refração e reflexão com base no índice de refração.
\end{itemize}

\begin{verbatim}

Material :: struct {
    scatter: #type proc(self: ^Material, ray: Ray, hit: Hit) -> (attenuation: Color, scattered: Ray, ok: bool),
}

Shit_Diffuse_Material  :: struct {
    using _ : Material,
    albedo: Color,
}

Lambertian_Material :: struct {
    using _ : Material,
    albedo: Color,
}

Metal_Material :: struct {
    using _ : Material,
    albedo: Color,
    fuzz: f32,
}

Dielectric_Material :: struct {
    using _ : Material,
    ir: f32, // índice de refração
};
\end{verbatim}

\subsection{Mecanismo de Reflexão de Raios}

O mecanismo central do \textit{ray tracer} envolve traçar raios pela cena, determinar suas interações com superfícies e calcular os valores de cor resultantes. O processo de reflexão de raios consiste nos seguintes passos:

\begin{enumerate}
\item \textbf{Geração de Raios}: Raios são gerados a partir do ponto de vista da câmera e projetados na cena.
\item \textbf{Detecção de Colisão}: Cada raio é testado quanto à interseção com objetos na cena.
\item \textbf{Interação de Material}: Após a colisão, os raios interagem com o material da superfície, determinando atenuação e raios dispersos com base nas propriedades do material.
\item \textbf{Traçado Recursivo}: Se um raio se dispersa, o processo se repete, traçando o caminho do raio disperso até que uma profundidade máxima de recursão seja atingida ou o raio escape da cena.
\item \textbf{Acúmulo de Cor}: Os valores de cor são acumulados ao longo do caminho do raio, essa acumulação simula a irradiância de um certo ponto da superfície.

\end{enumerate}

% \include{Conteudo/02_Comandos}

% \include{Conteudo/03_ConteudoEspecifico}
% \include{Conteudo/04_Outros}
% \include{Conteudo/05_Customizacao}
% \include{Conteudo/06_Conclusao}

\phantompart
\bibliography{Bibliografia}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ELEMENTOS PÓS-TEXTUAIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\postextual

\renewcommand{\chapnumfont}{\chaptitlefont}
\renewcommand{\afterchapternum}{}
% \include{Pos_Textual/Apendices}
% \include{Pos_Textual/Anexos}

\end{document}
